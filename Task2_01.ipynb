{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQqw56ZyPkSDuzB8dRAhvQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsuli/LSC_project/blob/main/Task2_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uYtp3TS6Dx5",
        "outputId": "fdf9b1e8-1420-486b-9a5b-51b4df1966cc"
      },
      "source": [
        "# specify the data file name and url\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00240/'\n",
        "datafile = url + 'UCI%20HAR%20Dataset.zip'\n",
        "\n",
        "# download the zip file from the web server using curl\n",
        "!curl $datafile --output UCI_HAR_Dataset.zip\n",
        "\n",
        "# unzip the file\n",
        "!unzip -qq UCI_HAR_Dataset.zip\n",
        "\n",
        "# change the directory name to remove spaces\n",
        "!mv -f UCI\\ HAR\\ Dataset UCI_HAR_DATASET"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 58.1M  100 58.1M    0     0  57.8M      0  0:00:01  0:00:01 --:--:-- 57.8M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fam53HA_6PMa"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3VqZGrz6ZOQ",
        "outputId": "03bda722-15f2-4c36-a46a-16317d24f693"
      },
      "source": [
        "# load the features and labels (subtract 1 as the labels aren't indexed from 0)\n",
        "ytest = np.loadtxt('UCI_HAR_DATASET/test/y_test.txt').astype(np.float32) -1\n",
        "ytrain = np.loadtxt('UCI_HAR_DATASET/train/y_train.txt').astype(np.float32) -1\n",
        "\n",
        "# load the x,y,z body accelerations test data\n",
        "xx=np.loadtxt('/content/UCI_HAR_DATASET/test/Inertial Signals/body_acc_x_test.txt').astype(np.float32) \n",
        "yy=np.loadtxt('/content/UCI_HAR_DATASET/test/Inertial Signals/body_acc_y_test.txt').astype(np.float32) \n",
        "zz=np.loadtxt('/content/UCI_HAR_DATASET/test/Inertial Signals/body_acc_z_test.txt').astype(np.float32) \n",
        "\n",
        "# concatenate the arrays along the last dimension\n",
        "xtest = np.concatenate((xx[:,:,None],yy[:,:,None],zz[:,:,None]),axis=2)\n",
        "# (using None here adds an extra dimension of size 1 to the end of the array)\n",
        "\n",
        "# follow the same approach for the train data\n",
        "xx=np.loadtxt('/content/UCI_HAR_DATASET/train/Inertial Signals/body_acc_x_train.txt').astype(np.float32) \n",
        "yy=np.loadtxt('/content/UCI_HAR_DATASET/train/Inertial Signals/body_acc_y_train.txt').astype(np.float32) \n",
        "zz=np.loadtxt('/content/UCI_HAR_DATASET/train/Inertial Signals/body_acc_z_train.txt').astype(np.float32) \n",
        "\n",
        "xtrain = np.concatenate((xx[:,:,None],yy[:,:,None],zz[:,:,None]),axis=2)\n",
        "\n",
        "xtrain, xvalid, ytrain, yvalid = train_test_split(xtrain, ytrain, test_size=0.2, random_state=42)\n",
        "ytrain_enc = tf.keras.utils.to_categorical(ytrain)\n",
        "yvalid_enc = tf.keras.utils.to_categorical(yvalid)\n",
        "ytest_enc = tf.keras.utils.to_categorical(ytest)\n",
        "print(xtrain.shape, ytrain_enc.shape, xvalid.shape, yvalid_enc.shape, xtest.shape, ytest_enc.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5881, 128, 3) (5881, 6) (1471, 128, 3) (1471, 6) (2947, 128, 3) (2947, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT5OMfHW2VMs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2fjjuM55lo"
      },
      "source": [
        "# input layer: xtrain, ytrain\n",
        "\n",
        "conv_layer = tf.keras.layers.Conv1D(filters=32, kernel_size=(4),activation=tf.nn.relu,padding='same')\n",
        "BatchNorm_layer = tf.keras.layers.BatchNormalization()\n",
        "ReLu_layer = tf.keras.layers.ReLU()\n",
        "pooling_layer = tf.keras.layers.AveragePooling1D()\n",
        "dense_layer = tf.keras.layers.Dense(units=10,activation=tf.nn.softmax)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZUBzWn2ayhy"
      },
      "source": [
        "def predict(x):\n",
        "    x = conv_layer(x)\n",
        "    x = BatchNorm_layer(x)\n",
        "    x = ReLu_layer(x)\n",
        "    x = pooling_layer(x)\n",
        "    output_layer = dense_layer(x)\n",
        "    \n",
        "    return output_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFuWE5sabFmz"
      },
      "source": [
        "@tf.function\n",
        "def loss(x,y):\n",
        "    y_ = predict(x)\n",
        "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.math.log(y_), axis=[1]))\n",
        "    return cross_entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNd0kTwWb8Oj"
      },
      "source": [
        "lr = 0.0001\n",
        "train_steps = 1000\n",
        "# we'll use the Adam optimizer instead of gradient descent.\n",
        "optimizer = tf.optimizers.Adam(lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "PWW3csnzb_x9",
        "outputId": "b82270fa-104a-4880-c5e1-b7d76c500653"
      },
      "source": [
        "for i in range(train_steps):\n",
        "    with tf.GradientTape() as tape:\n",
        "        current_loss = loss(xtrain,ytrain_enc)\n",
        "        gradients = tape.gradient(current_loss, tape.watched_variables())\n",
        "        optimizer.apply_gradients(zip(gradients, tape.watched_variables()))\n",
        "        if i%100 == 0:\n",
        "            print('Training Step:' + str(i) + ' Loss = ' + str(current_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e255ee36cca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHwm2tf0gdhZ",
        "outputId": "3ebada35-9bb5-4bd1-d4d5-2c89dca93e2c"
      },
      "source": [
        "type(xtrain)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOOkmsZXhE9U",
        "outputId": "6a588a4c-b036-40b7-a9e1-8b4ae411af3c"
      },
      "source": [
        "loss(xtrain)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5881, 64, 7), dtype=float32, numpy=\n",
              "array([[[0.1429282 , 0.14294979, 0.14269814, ..., 0.14267974,\n",
              "         0.14280616, 0.1429682 ],\n",
              "        [0.14295633, 0.14290585, 0.14274353, ..., 0.14275739,\n",
              "         0.14278714, 0.14292538],\n",
              "        [0.14284709, 0.1428807 , 0.14290573, ..., 0.1427768 ,\n",
              "         0.14281234, 0.14292705],\n",
              "        ...,\n",
              "        [0.14321564, 0.14309932, 0.14237055, ..., 0.14261702,\n",
              "         0.14269866, 0.14288303],\n",
              "        [0.14304072, 0.14302532, 0.14263614, ..., 0.14274581,\n",
              "         0.14271623, 0.1426857 ],\n",
              "        [0.14283477, 0.1430172 , 0.14281273, ..., 0.14268729,\n",
              "         0.14280511, 0.14263016]],\n",
              "\n",
              "       [[0.14211537, 0.15021092, 0.13626702, ..., 0.134828  ,\n",
              "         0.14219688, 0.135444  ],\n",
              "        [0.14886558, 0.14664815, 0.1344754 , ..., 0.13806891,\n",
              "         0.14013177, 0.13752423],\n",
              "        [0.15077233, 0.15003264, 0.13011765, ..., 0.13428465,\n",
              "         0.13516256, 0.14262545],\n",
              "        ...,\n",
              "        [0.14689939, 0.1546066 , 0.13232721, ..., 0.1329473 ,\n",
              "         0.13890573, 0.13444452],\n",
              "        [0.1493852 , 0.15085074, 0.12626721, ..., 0.135508  ,\n",
              "         0.14116824, 0.13507782],\n",
              "        [0.15563509, 0.14302987, 0.1351831 , ..., 0.13411267,\n",
              "         0.14159584, 0.13644165]],\n",
              "\n",
              "       [[0.14422388, 0.14437124, 0.13975804, ..., 0.14056385,\n",
              "         0.14279191, 0.1429835 ],\n",
              "        [0.14473125, 0.14300689, 0.14310081, ..., 0.14001605,\n",
              "         0.14096923, 0.14384031],\n",
              "        [0.13999304, 0.14796028, 0.14493869, ..., 0.13717115,\n",
              "         0.14194663, 0.14336042],\n",
              "        ...,\n",
              "        [0.15233123, 0.15137795, 0.12896815, ..., 0.13410057,\n",
              "         0.13885798, 0.14382865],\n",
              "        [0.14964654, 0.14956973, 0.13599856, ..., 0.1366063 ,\n",
              "         0.13511048, 0.1378484 ],\n",
              "        [0.13709103, 0.15335333, 0.14172815, ..., 0.13347039,\n",
              "         0.14186433, 0.13403036]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.13711344, 0.14998782, 0.14583667, ..., 0.13198766,\n",
              "         0.13927408, 0.13740416],\n",
              "        [0.13385752, 0.1536189 , 0.14613162, ..., 0.13062419,\n",
              "         0.14071846, 0.13644908],\n",
              "        [0.13502558, 0.15373486, 0.14363395, ..., 0.12993604,\n",
              "         0.14133778, 0.1367518 ],\n",
              "        ...,\n",
              "        [0.15199968, 0.15001139, 0.13329943, ..., 0.13398463,\n",
              "         0.13502641, 0.1427435 ],\n",
              "        [0.14651497, 0.14404127, 0.14218397, ..., 0.13912074,\n",
              "         0.14080852, 0.14071126],\n",
              "        [0.14263768, 0.14395794, 0.14145666, ..., 0.14148286,\n",
              "         0.14354254, 0.14329237]],\n",
              "\n",
              "       [[0.14263698, 0.14316899, 0.14308721, ..., 0.14225145,\n",
              "         0.14277583, 0.14298281],\n",
              "        [0.1425919 , 0.14315979, 0.14322838, ..., 0.14197107,\n",
              "         0.14284608, 0.14299153],\n",
              "        [0.14236854, 0.14337839, 0.14325406, ..., 0.141915  ,\n",
              "         0.14299299, 0.14292634],\n",
              "        ...,\n",
              "        [0.14278063, 0.14294544, 0.14296404, ..., 0.14264026,\n",
              "         0.1428475 , 0.14290692],\n",
              "        [0.14280038, 0.14306395, 0.14284639, ..., 0.1426607 ,\n",
              "         0.14288265, 0.14285424],\n",
              "        [0.14302179, 0.14284977, 0.14275445, ..., 0.14279217,\n",
              "         0.14278083, 0.14280583]],\n",
              "\n",
              "       [[0.14875652, 0.14772274, 0.1349386 , ..., 0.13700917,\n",
              "         0.14013176, 0.1410257 ],\n",
              "        [0.15294676, 0.14665517, 0.13556133, ..., 0.13730165,\n",
              "         0.13634323, 0.13846454],\n",
              "        [0.14828496, 0.15049978, 0.13240024, ..., 0.13162172,\n",
              "         0.1378223 , 0.14703403],\n",
              "        ...,\n",
              "        [0.15294117, 0.14439873, 0.13620009, ..., 0.13624224,\n",
              "         0.13919564, 0.1394026 ],\n",
              "        [0.15266065, 0.1462447 , 0.13593511, ..., 0.13750593,\n",
              "         0.13610722, 0.14081441],\n",
              "        [0.14533615, 0.14826259, 0.13438092, ..., 0.13802134,\n",
              "         0.1424406 , 0.14372917]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FXAj-zKhLsz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGyO59JShCzz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsrOOulsggzm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}